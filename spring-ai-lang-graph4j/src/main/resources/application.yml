# Undertow settings
server:
  port: ${SERVER_PORT:8082}
  undertow:
    threads:
      io: ${UNDERTOW_IO_THREADS:1}
      worker: ${UNDERTOW_WORKER_THREADS:8}
    buffer-size: ${UNDERTOW_BUFFER_SIZE:1024}

# Logging settings
logging:
  level:
    root: ERROR
    org:
      springframework:
        web: ERROR
        security: INFO
        boot: INFO
        ai: INFO
      hibernate: INFO
    com:
      github: DEBUG
  file:
    path: ${LOGGING_FILE_PATH:./}
    name: output.log
  logback:
    rollingpolicy:
      max-file-size: ${LOGGING_FILE_MAX_SIZE:300MB}
      max-history: ${LOGGING_FILE_MAX_HISTORY:3}

# Spring settings
spring:
  profiles:
    active: dev
  application:
    name: spring-ai-lang-graph4j
  data:
    redis:
      host: localhost
      port: 6379
      password: demo
      database: 0
      lettuce:
        pool:
          max-active: 8
          max-idle: 8
          min-idle: 0
          max-wait: -1ms
      timeout: 5000ms

# LangChain4j settings
langchain4j:
  open-ai:
    chat-model:
      base-url: https://api.openai.com/v1
      api-key: demo
      model-name: gpt-4o-mini
      temperature: 0.5
      max-tokens: 2000
      timeout: 60s
      log-requests: true
      log-responses: true
    streaming-chat-model:
      base-url: https://api.openai.com/v1
      api-key: demo
      model-name: gpt-4o-mini
      temperature: 0.5
      max-tokens: 2000
      timeout: 60s
      log-requests: true
      log-responses: true